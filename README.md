# Gpt_model
This notebook demonstrates the implementation of a Transformer model for English-French translation. It covers data loading and preprocessing, building the Transformer architecture using custom layers for positional embedding, self-attention, cross-attention, and feed-forward networks, and preparing the data for training using TensorFlow Datasets.
